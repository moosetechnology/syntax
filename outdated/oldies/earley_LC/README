
Pierre Boullier -- 31/07/2023

On suppose que les chaînes d’ARN forment un langage CF (i.e., context-free, 
hors contexte) sur les terminaux (bases) A, U, C, G. 

La grammaire est très ambigüe. Sur chaque arbre on évalue une énergie totale 
fondée sur la composition des énergies locales de liaisons (des bases) et on 
choisit l’arbre d’énergie minimale.  La structure CF montre alors les 
repliements du brin d’ARN (par exemple si «  … A … U … »  est une structure 
bien parenthésée sur A,U, alors A et U se touchent — sont appariés —).  

Cette approche «  linguistique » par des CFG est un peu trop grossière car 
elle rate des structures réelles non bien parenthésées (au sens CF du terme). 
Par exemple la chaîne « ACUG » où « AU » et « CG » sont appariés — « ({)} »
 dans notre vie courante — n’est pas CF.  Il y a donc eu des modélisations de 
l’ARN (et + généralement des protéines) qui utilisent des TAG et d’autres 
formalismes linguistiques.

L'exemple ARN a été ma première confrontation avec un vrai (pas jouet) 
analyseur (pas reconnaisseur) CF général. Cet exemple a été le déclencheur 
qui m’a fait m’intéresser (vraiment) à des analyseurs CF généraux (avant,
je me contentais de les enseigner !).  

J’ai donc fait un vrai analyseur à la Earley qui a servi de démonstrateur.
Puis je me suis intéressé à la linguistique où la manipulation de l’ambiguïté 
(donc d’un analyseur CF général) est inévitable. Je suis donc passé d'un
analyseur Earley « dédié » à l’ARN (outdated/oldies/earley) à un analyseur
Earley général (dont la dernière version doit se trouver dans 
extensions/src/earley_parser.c).

Puis l’analyseur Earley est devenu le coeur de tous les analyseurs syntaxiques 
de SYNTAX (linguistique), même pour les formalismes contextuels (LIG, TAG, …, 
et même RCG) en particulier par mon mécanisme d’analyse par « guides »
(voir ci-dessous pour une description).

Ainsi, le parser Earley est appelé dans beaucoup de contextes et s’est 
complexifié de plus en plus, mais que je n’ai pas forcément mis à jour les 
vieilles applications (ARN — et peut-être d’autres--) avec cette 
dernière version de Earley.

Le principe d’une analyse guidée est le suivant.  Soit G(F) une grammaire 
d'un formalisme contextuel F. Soit G une CFG qui est construite automatiquement 
à partir de G(F) et qui décrit un sur-langage de L(G(F)) (le plus petit 
possible). Le but est d’analyser une chaîne s = a1 … an par  G(F).  On 
commence par analyser s par G dont le résultat est une forêt partagée F(G,s). 

Une forêt partagée est une structure qui permet sous une forme (très) compacte 
de représenter tous les arbres d’analyse (la grammaire est (très) ambigüe) 
d’une chaîne source s.  F(G,s) est une instance G(s) de G par s définie comme 
suit. C’est une CFG dont les productions sont de la forme 
    (A,k,j) -> (X1,i0,i1) … (Xp, ip-1,ip)
où A-> X1 … Xp est une production de G, k==i0<= i1<=i2…<=ip==j et 
chaque (Xh, ih-1,ih) dérive (par G) dans la sous-chaîne de s comprise entre 
les indices ih_1 et Ih (si ih-1==ih on dérive dans le vide). 

On peut noter que le langage défini par F(G,s) est le singleton {s}.  
L’avantage d’utiliser F(G,s) comme source pour une analyse par G(F) plutôt 
que s directement est que l’analyse CF a pu déjà éliminer (à un coût O(n^3)) 
un certain nombre d’analyses qui auraient nécessitées pour être éliminées un 
coût 0(n^q), q>3.  C’est un hack qui en pratique marche bien mais qui 
malheureusement ne change pas le min théorique pour F.


